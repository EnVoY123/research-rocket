{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from pony.orm import db_session, select\n",
    "from src.data.models import Project, Interview, LLMAnswer, db\n",
    "from datetime import datetime\n",
    "from loguru import logger\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:52:43.292706Z",
     "start_time": "2024-05-22T18:52:43.290575Z"
    }
   },
   "id": "994b822c3626a771",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "logger.add(\"logs/project.log\", level=\"DEBUG\", rotation=\"100 MB\", retention=\"7 days\",\n",
    "           format=\"{time} | {level} | file: {file} | module: {module} | func: {function} | {message}\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:50:20.448559Z",
     "start_time": "2024-05-22T18:50:20.437874Z"
    }
   },
   "id": "43ee96e057cbc1d7",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm_haiku = ChatAnthropic(api_key=ANTHROPIC_API_KEY, model=\"claude-3-haiku-20240307\", max_tokens=4096, temperature=0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:05:56.866406Z",
     "start_time": "2024-05-22T13:05:56.834983Z"
    }
   },
   "id": "13991b92ca9e9c27",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "questions = {\n",
    "    1: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\"],\n",
    "        \"previous_answers\": False,\n",
    "        \"text_template\": \"\"\"\n",
    "            Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "            \n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "            2. Выделите основные разделы или фазы интервью. Например: введение, общие вопросы, основные темы, заключительные замечания.\n",
    "            3. Для каждого выделенного основного раздела приведите не более пяти цитат из вопросов в этом разделе. Важно, чтобы цитаты были короткими, но описывали этот раздел как можно полнее. Используйте только цитаты из вопросов интервьюера. Если в цитате встречается имя интервьюера или респондента, то удалите это имя.\n",
    "            4 Верните окончательный ответ в формате json, где ключом будет название основного раздела интервью, а значениями список всех выбранных вами цитат. \n",
    "        \"\"\"\n",
    "    },\n",
    "    2: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\"],\n",
    "        \"previous_answers\": False,\n",
    "        \"text_template\": \"\"\"\n",
    "            Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "            2. Выделите ключевые фразы, словосочетания или предложения, отражающие важные идеи, концепции или опыт. \n",
    "            3. Присвоите получившимся выделенным сегментам короткие ярлыки. Используя короткие описательные фразы или слова, которые обобщают основную идею.\n",
    "            4. Верните окончательный ответ в формате json, где ключом будет короткий ярлык, а значениями будут описания этого кода-ярлыка.\n",
    "            \"\"\"\n",
    "    },\n",
    "    3: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\", \"previous_answers\"],\n",
    "        \"previous_answers\": True,\n",
    "        \"text_template\": \"\"\"\n",
    "            Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "            2. Просмотрите тематические коды <interview_code>{previous_answers}</interview_code> и найдите среди них сходства или взаимосвязи.\n",
    "            3. Сгруппируйте связанные тематические коды в более широкие категории или темы, которые охватывают основные темы, обсуждавшиеся в интервью.\n",
    "            4. Определите любые подтемы в рамках каждой основной темы, чтобы обеспечить более детальное понимание тем.\n",
    "            5. Верните окончательный ответ в формате json, где ключами будут основные темы, а значениями список подтем. \n",
    "            \"\"\"\n",
    "    },\n",
    "    4: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\"],\n",
    "        \"previous_answers\": False,\n",
    "        \"text_template\": \"\"\"\n",
    "            Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "            2. Составьте список всех конкретных проблем, упомянутых респондентами.\n",
    "            2. Подсчитайте, сколько раз упоминалась каждая проблема. \n",
    "            3. Верните окончательный ответ в формате json, где ключами будут проблемы, а значениями количество упоминаний проблем в интервью. \n",
    "            \"\"\"\n",
    "    },\n",
    "    5: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\", \"previous_answers\"],\n",
    "        \"previous_answers\": True,\n",
    "        \"text_template\": \"\"\"\n",
    "            Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "            2. Просмотрите список проблем <interview_problems>{previous_answers}</interview_problems> и найдите среди них сходства или взаимосвязи.\n",
    "            3. Сгруппируйте связанные проблемы в более широкие типы проблем, которые охватывают различные упомянутые проблемы в интервью. \n",
    "            4. Верните окончательный ответ в формате json, где ключами будут широкие типы проблем, а значениями списки проблем входящих в них.\n",
    "            \"\"\"\n",
    "    },\n",
    "    6: {\n",
    "        \"llm_temperature\": 0.0,\n",
    "        \"input_variables\": [\"raw_interview\", \"previous_answers\"],\n",
    "        \"previous_answers\": True,\n",
    "        \"text_template\": \"\"\"\n",
    "             Пожалуйста, внимательно прочтите предоставленное вам интервью и категории проблем, которые были выявлены при первичном анализе данного интервью: <interview>{raw_interview}</interview> and <interview_problems>{previous_answers}</interview_problems> \n",
    "             \n",
    "            Пошаговые инструкции:\n",
    "            1. Используйте только информацию, предоставленную вам в интервью и в выявленных категориях проблем, не придумывайте ничего самостоятельно.\n",
    "            \n",
    "            2. Проанализируйте темы и частоту возникновения проблем и их категории. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"reflections\", вложенными ключами будут категория проблем, а значениями будет список содержащий результаты проведенного анализа.  \n",
    "            \n",
    "            3. Проанализируйте, что результаты \"reflections\" говорят об опыте, взглядах или трудностях респондента. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"results\", вложенными ключами будут категория опыта, а значениями будет список содержащий результаты проведенного анализа.\n",
    "            \n",
    "            4. Обратите внимание на любые неожиданные закономерности, связи или контрасты в данных. Поделитесь этими наблюдениями. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"unexpected\", вложенными ключами будут категория контрастов, а значениями будет список содержащий результаты проведенного анализа.\n",
    "            \n",
    "            5. Разработайте предварительные объяснения или гипотезы о том, почему возникли определенные темы или проблемы и как они могут быть связаны друг с другом или с более широкими контекстуальными факторами. Дайте ответ в форме json, где будет только один ключ – \"hypothesis\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "            \n",
    "            6. Рассмотрите альтернативные объяснения и контрпримеры, чтобы прояснить гипотезы сформированные в разделе \"hypothesis\". Дайте ответ в форме json, где будет только один ключ – \"alternatives\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "            \n",
    "            7. Укажите области, в которых могут потребоваться дополнительные исследования или анализ для подтверждения ваших идей из раздела \"alternatives\". Дайте ответ в форме json, где будет только один ключ – \"additional\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "            \"\"\"\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:50:31.705474Z",
     "start_time": "2024-05-22T18:50:31.697082Z"
    }
   },
   "id": "initial_id",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Класс для работы с LLM\n",
    "class LLMProcessor:\n",
    "    def __init__(self, llm, questions, interview):\n",
    "        self.llm = llm\n",
    "        self.questions = questions\n",
    "        self.interview = interview\n",
    "        self.previous_answers = {}\n",
    "\n",
    "    @db_session\n",
    "    def save_llm_answer(self, question, metadata, prompt, response, content):\n",
    "\n",
    "        LLMAnswer(\n",
    "            project=1,\n",
    "            interview=1,\n",
    "            analysis_step=int(question),\n",
    "            created=datetime.now(),\n",
    "            model=str(metadata['model']),\n",
    "            input_tokens=int(metadata['input_tokens']),\n",
    "            output_tokens=int(metadata['output_tokens']),\n",
    "            prompt=str(prompt),\n",
    "            answer_full=str(response),\n",
    "            answer_clear=content\n",
    "        )\n",
    "        db.commit()\n",
    "\n",
    "    def get_response_json(self, response):\n",
    "        metadata = {\n",
    "            \"model\": response.response_metadata[\"model\"],\n",
    "            \"input_tokens\": response.response_metadata[\"usage\"][\"input_tokens\"],\n",
    "            \"output_tokens\": response.response_metadata[\"usage\"][\"output_tokens\"]\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            content = json.loads(response.content)\n",
    "        except Exception as e:\n",
    "            content = None\n",
    "            logger.error(f\"get_response_json: {e}\")\n",
    "\n",
    "        return metadata, content\n",
    "\n",
    "    def get_prompt(self, question):\n",
    "        ru_lang = \"\\nВнимание, это важно! Всегда отправляйте полный текст ответа только на русском языке. Спасибо!\"\n",
    "        prompt = PromptTemplate(template=self.questions[question]['text_template'] + ru_lang,\n",
    "                                input_variables=self.questions[question]['input_variables'])\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def process_steps(self):\n",
    "        try:\n",
    "            for question in tqdm(sorted(self.questions.keys())):\n",
    "                prompt = self.get_prompt(question)\n",
    "                chain = prompt | self.llm\n",
    "\n",
    "                if self.questions[question]['previous_answers'] is True:\n",
    "                    previous_answers = self.previous_answers[question - 1]\n",
    "                else:\n",
    "                    previous_answers = None\n",
    "\n",
    "                response = chain.invoke({\"raw_interview\": self.interview, \"previous_answers\": previous_answers})\n",
    "                metadata, content = self.get_response_json(response)\n",
    "                self.previous_answers[question] = content\n",
    "                self.save_llm_answer(\n",
    "                    question=question, metadata=metadata, prompt=prompt, response=response, content=content\n",
    "                )\n",
    "                time.sleep(60)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"{e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:50:34.717141Z",
     "start_time": "2024-05-22T18:50:34.709525Z"
    }
   },
   "id": "6b6fd56cdf9794d0",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "processor = LLMProcessor(llm=llm_haiku, questions=questions, interview=raw_interview)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:50:43.641748Z",
     "start_time": "2024-05-22T18:50:43.639330Z"
    }
   },
   "id": "459e4e0797895120",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# processor.process_steps()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:57:08.238496Z",
     "start_time": "2024-05-22T18:57:08.236782Z"
    }
   },
   "id": "265f445347ce7f34",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# @db_session\n",
    "# def get_all_interviews_project(project_id: int = None):\n",
    "#     results = {}\n",
    "#     interviews = select(i for i in Interview if i.project.id == project_id)\n",
    "#     for interview in interviews:\n",
    "#         results[interview.id] = interview.content\n",
    "# \n",
    "#     return results\n",
    "# \n",
    "# \n",
    "# get_all_interviews_project(project_id=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T19:18:06.730218Z",
     "start_time": "2024-05-22T19:18:06.728428Z"
    }
   },
   "id": "7136d1e0c9182ad",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T19:01:20.157822Z",
     "start_time": "2024-05-22T19:01:20.156557Z"
    }
   },
   "id": "b136ffaa92952081",
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T10:54:58.847818Z",
     "start_time": "2024-05-22T10:54:58.845681Z"
    }
   },
   "id": "ba54e446cb20426",
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:15:03.408358Z",
     "start_time": "2024-05-22T13:15:03.407033Z"
    }
   },
   "id": "efe5ebee55d80224",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4afd1d1e8871684"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
