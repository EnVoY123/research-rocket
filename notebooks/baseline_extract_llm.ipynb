{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T17:45:11.465828Z",
     "start_time": "2024-05-18T17:45:11.462112Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:12:28.033106Z",
     "start_time": "2024-05-18T16:12:27.900338Z"
    }
   },
   "id": "d5ec38a4aba03b81",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0, file: interview_2.txt, length: 33951, tokens: 15518.\n",
      "index: 1, file: interview_1.txt, length: 36025, tokens: 16647.\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\"../data/demo\", glob=\"*.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "for num, doc in enumerate(documents):\n",
    "    print(\n",
    "        f\"index: {num}, file: {doc.metadata['source'][-15:]}, length: {len(doc.page_content)}, tokens: {len(encoding.encode(doc.page_content))}.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:12:41.632567Z",
     "start_time": "2024-05-18T16:12:38.422442Z"
    }
   },
   "id": "f7ca385dfce9928e",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "interview_1 = documents[0].page_content\n",
    "interview_2 = documents[1].page_content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:12:46.627825Z",
     "start_time": "2024-05-18T16:12:46.624602Z"
    }
   },
   "id": "a2b40225d2141350",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "llm_haiku = ChatAnthropic(api_key=ANTHROPIC_API_KEY, model=\"claude-3-haiku-20240307\", max_tokens=4096, temperature=0.0)\n",
    "llm_haiku_t = ChatAnthropic(api_key=ANTHROPIC_API_KEY, model=\"claude-3-haiku-20240307\", max_tokens=4096, temperature=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:51:23.380726Z",
     "start_time": "2024-05-18T18:51:23.314414Z"
    }
   },
   "id": "32d7fd0ee559a056",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def asks_llm(llm: None, raw_data: list[str] = None, text_template: str = None, input_variables: list[str] = None):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param llm: \n",
    "    :param raw_interview: \n",
    "    :param text_template: \n",
    "    :param input_variables: \n",
    "    :param input_chain: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    upd = \"\\nAttention, this is important! Always send the full text of the response in Russian only. Thanks!\"\n",
    "\n",
    "    prompt = PromptTemplate(input_variables=input_variables, template=text_template + upd)\n",
    "    chain = prompt | llm\n",
    "\n",
    "    input_chain = {}\n",
    "    for var, data in zip(input_variables, raw_data):\n",
    "        input_chain[var] = data\n",
    "\n",
    "    answer = chain.invoke(input_chain)\n",
    "    return answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T17:00:15.138850Z",
     "start_time": "2024-05-18T17:00:15.136444Z"
    }
   },
   "id": "e00ee8f3ece9420a",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_llm_response(raw_answer):\n",
    "    metadata = {\n",
    "        \"model\": raw_answer.response_metadata[\"model\"],\n",
    "        \"input_tokens\": raw_answer.response_metadata[\"usage\"][\"input_tokens\"],\n",
    "        \"output_tokens\": raw_answer.response_metadata[\"usage\"][\"output_tokens\"]\n",
    "    }\n",
    "\n",
    "    content = json.loads(raw_answer.content)\n",
    "\n",
    "    return metadata, content"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T17:29:53.246417Z",
     "start_time": "2024-05-18T17:29:53.243132Z"
    }
   },
   "id": "632f76b14367593c",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_1 = asks_llm(\n",
    "    llm=llm_haiku, raw_data=[interview_1],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "        2. Выделите основные разделы или фазы интервью. Например: введение, общие вопросы, основные темы, заключительные замечания.\n",
    "        3. Для каждого выделенного основного раздела приведите не более пяти цитат из вопросов в этом разделе. Важно, чтобы цитаты были короткими, но описывали этот раздел как можно полнее. Используйте только цитаты из вопросов интервьюера. Если в цитате встречается имя интервьюера или респондента, то удалите это имя.\n",
    "        4 Верните окончательный ответ в формате json, где ключом будет название основного раздела интервью, а значениями список всех выбранных вами цитат. \n",
    "        \"\"\",\n",
    "    input_variables=[\"raw_interview\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T17:44:31.561972Z",
     "start_time": "2024-05-18T17:44:21.784738Z"
    }
   },
   "id": "b5361fc843a75d63",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_1_metadata, answer_1_content = extract_llm_response(answer_1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T17:44:33.039697Z",
     "start_time": "2024-05-18T17:44:33.036857Z"
    }
   },
   "id": "40d5260982c14f65",
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_2 = asks_llm(\n",
    "    llm=llm_haiku, raw_data=[interview_1],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "        2. Выделите ключевые фразы, словосочетания или предложения, отражающие важные идеи, концепции или опыт. \n",
    "        3. Присвоите получившимся выделенным сегментам короткие ярлыки. Используя короткие описательные фразы или слова, которые обобщают основную идею.\n",
    "        4. Верните окончательный ответ в формате json, где ключом будет короткий ярлык, а значениями будут описания этого кода-ярлыка.\n",
    "        \"\"\",\n",
    "    input_variables=[\"raw_interview\"],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:01:36.863225Z",
     "start_time": "2024-05-18T18:01:24.023377Z"
    }
   },
   "id": "2fbb698a4c3e4c53",
   "execution_count": 171
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_2_metadata, answer_2_content = extract_llm_response(answer_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:01:39.548591Z",
     "start_time": "2024-05-18T18:01:39.546128Z"
    }
   },
   "id": "50c6ad07a008f48c",
   "execution_count": 172
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_2_codes = \", \".join(list(answer_2_content.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:01:45.950074Z",
     "start_time": "2024-05-18T18:01:45.947134Z"
    }
   },
   "id": "4e0c9a424bdc3359",
   "execution_count": 174
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_3 = asks_llm(\n",
    "    llm=llm_haiku, raw_data=[interview_1, answer_2_codes],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "        2. Просмотрите тематические коды <interview_code>{interview_code}</interview_code> и найдите среди них сходства или взаимосвязи.\n",
    "        3. Сгруппируйте связанные тематические коды в более широкие категории или темы, которые охватывают основные темы, обсуждавшиеся в интервью.\n",
    "        4. Определите любые подтемы в рамках каждой основной темы, чтобы обеспечить более детальное понимание тем.\n",
    "        5. Верните окончательный ответ в формате json, где ключами будут основные темы, а значениями список подтем. \n",
    "        \"\"\",\n",
    "    input_variables=[\"raw_interview\", \"interview_code\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:31:43.997320Z",
     "start_time": "2024-05-18T18:31:38.045287Z"
    }
   },
   "id": "eb31613224a7ae53",
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_3_metadata, answer_3_content = extract_llm_response(answer_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:31:45.172374Z",
     "start_time": "2024-05-18T18:31:45.169266Z"
    }
   },
   "id": "acddfaf82b6e0b19",
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_4 = asks_llm(\n",
    "    llm=llm_haiku, raw_data=[interview_1],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "        2. Составьте список всех конкретных проблем, упомянутых респондентами.\n",
    "        2. Подсчитайте, сколько раз упоминалась каждая проблема. \n",
    "        3. Верните окончательный ответ в формате json, где ключами будут проблемы, а значениями количество упоминаний проблем в интервью. \n",
    "        \"\"\",\n",
    "    input_variables=[\"raw_interview\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:34:10.325876Z",
     "start_time": "2024-05-18T18:34:07.226748Z"
    }
   },
   "id": "e0132a4138bc55fb",
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_4_metadata, answer_4_content = extract_llm_response(answer_4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:34:13.611404Z",
     "start_time": "2024-05-18T18:34:13.608760Z"
    }
   },
   "id": "72544a9895e826cf",
   "execution_count": 204
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_4_problems = \", \".join(list(answer_4_content.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:35:17.922312Z",
     "start_time": "2024-05-18T18:35:17.920211Z"
    }
   },
   "id": "99a4b65d11595c5",
   "execution_count": 207
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_5 = asks_llm(\n",
    "    llm=llm_haiku, raw_data=[interview_1, answer_4_problems],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и следуйте приведенным ниже пошаговым инструкциям: <interview>{raw_interview}</interview>\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью, не придумывайте ничего самостоятельно.\n",
    "        2. Просмотрите список проблем <interview_problems>{interview_problems}</interview_problems> и найдите среди них сходства или взаимосвязи.\n",
    "        2. Сгруппируйте связанные проблемы в более широкие типы проблем, которые охватывают различные упомянутые проблемы в интервью. \n",
    "        \n",
    "        4. Верните окончательный ответ в формате json, где ключами будут широкие типы проблем, а значениями списки проблем входящих в них.\n",
    "        \"\"\",\n",
    "    input_variables=[\"raw_interview\", \"interview_problems\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:49:42.699485Z",
     "start_time": "2024-05-18T18:49:38.728419Z"
    }
   },
   "id": "c86b29b2c73bc117",
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_5_metadata, answer_5_content = extract_llm_response(answer_5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:50:07.735881Z",
     "start_time": "2024-05-18T18:50:07.732881Z"
    }
   },
   "id": "92055f1346826767",
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_5_group_problems = \", \".join(list(answer_5_content.keys()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T18:50:47.027916Z",
     "start_time": "2024-05-18T18:50:47.025469Z"
    }
   },
   "id": "15f1c97ecdc7070c",
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_6 = asks_llm(\n",
    "    llm=llm_haiku_t, raw_data=[interview_1, answer_5_group_problems],\n",
    "    text_template=\"\"\"\n",
    "        Пожалуйста, внимательно прочтите предоставленное вам интервью и категории проблем, которые были выявлены при первичном анализе данного интервью: <interview>{raw_interview}</interview> and <interview_problems>{interview_problems_categories}</interview_problems> \n",
    "\n",
    "\n",
    "        Пошаговые инструкции:\n",
    "        1. Используйте только информацию, предоставленную вам в интервью и в выявленных категориях проблем, не придумывайте ничего самостоятельно.\n",
    "        \n",
    "        2. Проанализируйте темы и частоту возникновения проблем и их категории. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"reflections\", вложенными ключами будут категория проблем, а значениями будет список содержащий результаты проведенного анализа.  \n",
    "        \n",
    "        3. Проанализируйте, что результаты \"reflections\" говорят об опыте, взглядах или трудностях респондента. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"results\", вложенными ключами будут категория опыта, а значениями будет список содержащий результаты проведенного анализа.\n",
    "        \n",
    "        4. Обратите внимание на любые неожиданные закономерности, связи или контрасты в данных. Поделитесь этими наблюдениями. Дайте ответ в форме вложенного json, верхнеуровневым ключом будет – \"unexpected\", вложенными ключами будут категория контрастов, а значениями будет список содержащий результаты проведенного анализа.\n",
    "        \n",
    "        5. Разработайте предварительные объяснения или гипотезы о том, почему возникли определенные темы или проблемы и как они могут быть связаны друг с другом или с более широкими контекстуальными факторами. Дайте ответ в форме json, где будет только один ключ – \"hypothesis\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "        \n",
    "        6. Рассмотрите альтернативные объяснения и контрпримеры, чтобы прояснить гипотезы сформированные в разделе \"hypothesis\". Дайте ответ в форме json, где будет только один ключ – \"alternatives\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "        \n",
    "        7. Укажите области, в которых могут потребоваться дополнительные исследования или анализ для подтверждения ваших идей из раздела \"alternatives\". Дайте ответ в форме json, где будет только один ключ – \"additional\", а значениями будет список содержащий результаты проведенного анализа.\n",
    "        \"\"\", \n",
    "    input_variables=[\"raw_interview\", \"interview_problems_categories\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:35:41.081762Z",
     "start_time": "2024-05-18T19:35:25.354060Z"
    }
   },
   "id": "dcaf3a7a32f72a9a",
   "execution_count": 237
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "answer_6_metadata, answer_6_content = extract_llm_response(answer_6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:36:12.998496Z",
     "start_time": "2024-05-18T19:36:12.996836Z"
    }
   },
   "id": "4344993ebd1f6cdf",
   "execution_count": 239
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"step_1\": answer_1_content,\n",
    "    \"step_2\": answer_2_content,\n",
    "    \"step_3\": answer_3_content,\n",
    "    \"step_4\": answer_4_content,\n",
    "    \"step_5\": answer_5_content,\n",
    "    \"step_6\": answer_6_content,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:40:25.118590Z",
     "start_time": "2024-05-18T19:40:25.116614Z"
    }
   },
   "id": "2648c2dd6f2b3d61",
   "execution_count": 249
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open(\"../data/demo/results_one_interview.json\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T19:48:32.234284Z",
     "start_time": "2024-05-18T19:48:32.230313Z"
    }
   },
   "id": "5537d90837f68335",
   "execution_count": 255
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "78d40d6570fd4662"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
